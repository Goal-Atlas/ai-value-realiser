Part 2: Why you need a verification-class mass spectrometer
This is the second in a multi-part blog series highlighting the key attributes and impressive benefits of the Stellar mass spectrometer—the first-of-its-kind instrument designed and optimized for highly multiplexed targeted quantitation, ideally suited—for discovery verification. See Part 1 and stay tuned for more blog posts in the series.
As artificial intelligence (AI) continues to take the modern world by storm, a similar concept in the scientific world called “automated intelligence” is revolutionizing work for research scientists in their transition from discovery to clinical validation. This version of AI enables you to leverage empirical data, user-defined guidance and instrument performance metrics to manage experiments and dramatically improve productivity.
It’s possible with an all-new instrument—the Thermo Scientific Stellar mass spectrometer (MS)—which uses AI to transform the process of building methods, data acquisition management and data processing for interpretation and planning next steps. Combined with the unique instrument performance, the Stellar mass spectrometer creates a new paradigm for targeted quantitation.
Garbage in, garbage out
Scientific research is all about data, and just like with any computational work, poor-quality input will always produce faulty or unusable output. This idea is especially true for clinical and translational researchers who perform biomarker verification. The quality of your method development and research will always be determined by several things: (1) your existing data (e.g., compound databases, empirical data, in silico predictive models), (2) your guidance (e.g., real-time decision-making parameters) and (3) the experimental capabilities of your instrument platform.
Another challenge: limitations in the discovery-to-validation workflow
Poor quality input for method development is one challenge, but it’s not the only one. As we discussed in our first blog post researchers have long struggled with a technology gap in available instrument platforms. Until recently, there were no single-vendor solutions that offered excellent performance for both discovery and targeted verification. This was a serious limitation that impacted how much researchers could rely on AI for method-building. The old process still required a lot more hands-on optimization, which seriously limited productivity.
Finally: automated intelligence without the drawbacks
With the advent of automated intelligence available on Stellar MS to build targeted methods and manage data acquisition, it’s a whole new ball game. Stellar MS software leverage automated intelligence to boost laboratory productivity, capacity, and lab reputation for high-quality data with faster turnaround times. As a researcher, you can now use automated intelligence to “feed in” your previous work and provide instructions about how to use that information to make decisions and generate new data. Here’s how it works:
How AI speeds method creation and optimization
Stellar MS come with the Thermo Scientific software tool PRM Conductor in Skyline software for automated method building. It uses automated intelligence to build highly effective, targeted acquisition methods from your discovery data (from either Thermo Scientific Orbitrap-based MS systems or the Stellar MS).
PRM Conductor aids in the generation of targeted-MS2 and MS3 assays. The creation of an assay is broken into three main parts:
- Skyline metadata describing precursor-to-product transitions is used to filter transitions against a set of thresholds. The filters are based on integrated peak area, relative area, signal-to-background, correlation to median transition, LC base peak width, and retention time. Precursors are filtered by whether they have at least a certain number of qualifying transitions, typically three for peptides and two for small molecules.
- Targeted assays are created with a visualization that depicts the concurrency of the assay in terms of how long the instrument would take to acquire data for the precursors as a function of retention time. Given a desired number of acquired points per LC peak and corresponding cycle time, you can see how various experimental parameters affect the feasibility of acquiring data for the qualifying precursors, such as linear ion trap scan rate and acquisition window width.
- Finally, you can decide whether to create multiple assays for all qualifying precursors, or a single assay with a “balanced load” that picks the best N peptides per protein. Instrument methods for the final assay(s) can then be exported, based on a user-defined template method.
In addition, Stellar MS solutions use Normalized Collision Energy (NCE) – a well-established principle that automatically compensates for mass dependency by automatically estimating all of the collision energies. NCE bypasses the need for optimization per precursor-to-product ion transition performed by a triple quadrupole mass spectrometer which takes much longer to perform, multiplies the experimental cost due to replicate injections of standards and dedicated research staff time.
How AI streamlines data acquisition
With the Stellar MS automated intelligence capabilities, scientists can also speed data acquisition with these tools:
Dynamic AGC (automated gain control) helps the system maintain constant ion count and high data quality regardless of ion flux. Essentially, the Stellar MS regulates the number of charges or ions per spectrum by employing a hyper-fast ion gate managing ion accumulation to pass an ideally constant number of ions per spectrum.
As depicted in Figure 1, the ability to vary the injection time expands the dynamic range of quantitation, from a base range given by just the storage and detector saturation limits and multiplies it by the gate linearity range. In the case of the Stellar MS, the pulsed nature of ion trap mass analysis limits the intra-scan dynamic range to about three orders (from 1 to 25k ions in a peak), while the gate can give a linear response from about 3d-6 seconds up to a practical experimental limit, for example 3e-1 seconds.
Another tool, Adaptive RT, dynamically manages PRM acquisition, which means you’ll nearly eliminate the risk of missing data while maximizing target capacity. Missing data requires you to re-run samples, costing time and money. Using the method (generated by PRM Conductor software), you can run one representative sample on the gradient and product ion distribution profiles as a function of retention time are built into the instrument editor, which combines PRM settings and Adaptive RT to manage every microsecond of sample acquisition. The system will continue to update and modify the method to adjust for any unexpected LC perturbation or manage data acquisition across multi-channel UHPLC column formats. For a more in-depth description, check out the newly published BioRxiv paper.
Conclusion: Automated intelligence maximizes workflow performance
In order to maximize LC-MSn workflow performance for translational verification, you need solutions that streamline all steps while meeting experimental expectations—scale, sensitivity, specificity, throughput, and ease-of-use. Together, automated intelligence on the Stellar MS combined with unique instrument performance can help deliver the ultimate performance to boost your lab’s productivity and prestige.
For more information, explore the Stellar MS web page or reach out to your Thermo Fisher Scientific sales representative.
Intrigued to learn more about the Stellar MS and how it can improve your work? Watch for more blog posts in this series soon.
Visit our LinkedIn page: #StellarMassSpec #MassSpectrometry #TranslationalResearch