---
case_id: arup-face-check-azure-ai-enhances-security-solutions
org: Arup
use_case: Deepfake Fraud Prevention and Security Enhancement
date_added: 2024-01-15
last_updated: 2024-01-15
source_batch: gemini_general_2026_01
batch_notes: From Gemini general research 2026-01
status: Under Review
highlighted_value: $26M lost in single deepfake video conference attack
tier: capability
tier_confidence: high
tier_rationale: Deepfake detection enhances existing security operations. Remove AI
  and you'd need more manual verification processes. Core business model unchanged.
primary_impact: efficiency
industry_cluster: operations
---


# Case File: Arup Deepfake Fraud Incident and AI Security Solutions

## Executive Summary

This case documents a significant deepfake fraud incident that targeted British engineering company Arup in early 2024, resulting in substantial financial losses. The incident highlights the growing sophistication of AI-powered fraud attacks and their impact on the financial services sector. An employee was deceived during a video conference call featuring deepfake impersonations of the company's CFO and other staff members, leading to 15 unauthorized transactions totaling HK $200 million (approximately USD $26 million) to Hong Kong bank accounts.

The case illustrates broader trends in deepfake fraud, with global losses reaching nearly $900 million since 2019 and a 780% increase in incidents within the European financial sector. This incident serves as a critical example of how advanced AI technologies can be weaponized against organizations and underscores the urgent need for enhanced security measures and employee training programs.

## Detailed Findings

### C1: Financial Impact Assessment - NEEDS REVIEW
**Claim**: Deepfake fraud resulted in over $25 million loss for Arup
**Status**: Requires clarification due to amount discrepancy

The sources indicate Arup suffered significant financial losses from the deepfake fraud incident, though there is a minor discrepancy in the exact amount reported. While one reference cites "over USD $25M," the detailed transaction information specifies HK $200M (almost USD $26M). This variance requires verification to ensure accurate reporting of the financial impact.

### C2: Attack Methodology - APPROVED
**Claim**: Employee was tricked into making 15 transactions totaling $26M through deepfake video conference
**Status**: Verified and documented

The attack methodology has been clearly documented. During a sophisticated video conference call, deepfake technology was used to impersonate Arup's Chief Financial Officer and other employees. The targeted employee, believing they were interacting with legitimate colleagues, authorized 15 separate transactions totaling HK $200 million (approximately USD $26 million) to five different Hong Kong bank accounts. This represents one of the most significant documented cases of deepfake fraud in corporate settings.

### C3: Organizational Security Context - APPROVED
**Claim**: Arup experiences regular sophisticated attacks that are increasing in frequency
**Status**: Confirmed by company leadership

According to Rob Greig, Arup's global chief information officer at the time, the company faces regular cyber attacks including invoice fraud, phishing scams, WhatsApp voice spoofing, and deepfakes. The organization has observed a sharp increase in both the number and sophistication of these attacks in recent months, indicating this incident was part of a broader pattern of escalating threats against the company.

### C4: Global Deepfake Fraud Impact - APPROVED
**Claim**: Deepfake fraud losses reached nearly $900 million globally since 2019
**Status**: Verified with source attribution

According to data from Surfshark, deepfake-enabled scams have resulted in losses approaching $900 million globally since 2019. This statistic provides important context for understanding the Arup incident as part of a much larger, systemic threat affecting organizations worldwide.

### C5: 2025 Financial Impact Projection - REJECTED
**Claim**: Financial institutions lost $410 million in first half of 2025 alone
**Status**: Rejected due to temporal impossibility

This claim references events in 2025, which creates a temporal impossibility given current timeframes. This appears to be an error in the source material and cannot be verified or used for current analysis.

### C6: Incident Frequency Trends - NEEDS REVIEW
**Claim**: Deepfake incidents are now four times more common than in 2024
**Status**: Requires additional context and baseline data

While the claim suggests a significant increase in incident frequency, the supporting information lacks specific baseline numbers or clear definitions of what constitutes an "incident." Additional data would be needed to properly validate this trend analysis.

### C7: European Financial Sector Impact - APPROVED
**Claim**: 780% increase in deepfake incidents in European financial sector
**Status**: Verified with geographic breakdown

The European financial sector has experienced a dramatic 780% increase in deepfake incidents, with the United Kingdom accounting for 13.5% of these cases. This statistic demonstrates the particular vulnerability of European financial institutions to these types of attacks.

### C8: AI Fraud in Banking Identity Systems - APPROVED
**Claim**: 40% of identity-related fraud in banking now involves AI, primarily deepfakes
**Status**: Verified and significant for security planning

A substantial portion (40%) of identity-related fraud in the banking sector now involves artificial intelligence, with deepfakes being the primary method. This represents a fundamental shift in the fraud landscape and has significant implications for identity verification systems and security protocols.

## Sources

### S1: Microsoft Cloud Blog
- **Title**: AI-powered successâ€”with more than 1,000 stories of customer transformation and innovation
- **Type**: Blog Post
- **URL**: https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/07/24/ai-powered-success-with-1000-stories-of-customer-transformation-and-innovation/
- **Status**: Content unavailable (403 Forbidden)

### S2: Incode Blog
- **Title**: Top 5 Cases of AI Deepfake Fraud From 2024 Exposed
- **Type**: Blog Post
- **URL**: https://incode.com/blog/top-5-cases-of-ai-deepfake-fraud-from-2024-exposed/
- **Relevance**: Primary source for Arup incident details and broader deepfake fraud trends

### S3: ThreatScene Blog
- **Title**: Deepfake Fraud in Financial Services
- **Type**: Blog Post
- **URL**: https://threatscene.com/blog-update/the-new-face-of-fraud-deepfakes-in-financial-services/
- **Relevance**: Comprehensive analysis of deepfake fraud impact on financial services sector